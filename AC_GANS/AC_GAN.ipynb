{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AC_GAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alX91EeT9F6t",
        "colab_type": "text"
      },
      "source": [
        "# Auxiliary Classifier with Generative Adversarial Network "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQEelfc4FBOW",
        "colab_type": "text"
      },
      "source": [
        "## Project Info\n",
        "this notebook is an implementation for Auxiliary Classifier with Generative Adversarial Network "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lOl15TnFGqy",
        "colab_type": "text"
      },
      "source": [
        "# Header\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-YtICsLFKAZ",
        "colab_type": "text"
      },
      "source": [
        " ## Import Necessary Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSGbzYY9FJUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Basic Level Libs\n",
        "import math\n",
        "import os \n",
        "\n",
        "#Mid Level Libs\n",
        "import numpy as np\n",
        "\n",
        "#FrameWorks\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "#Other\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqSGX3LqFN80",
        "colab_type": "text"
      },
      "source": [
        "## Mout Google Dirve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zbbuMbWG7Du",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "240438e4-3de0-41ee-d132-0b94c3e366fa"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_Cnnb-EEieQ",
        "colab_type": "text"
      },
      "source": [
        "# Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8bHLROmXLWL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "511d4970-4b72-4947-f1e7-14e1b8034ee5"
      },
      "source": [
        "batch_size_train = 64\n",
        "batch_size_test = 1000\n",
        "\n",
        "random_seed = 1\n",
        "torch.backends.cudnn.enabled = False\n",
        "torch.manual_seed(random_seed)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.5,), (0.5,))\n",
        "                             ])),\n",
        "    \n",
        "  batch_size=batch_size_train, shuffle=True)\n",
        "\n",
        "valid_loader = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.5,), (0.5,))\n",
        "                             ])),\n",
        "  batch_size=batch_size_test, shuffle=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /files/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:01, 8899902.54it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /files/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/28881 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /files/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 134341.57it/s]           \n",
            "  0%|          | 0/1648877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /files/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /files/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 2210273.33it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /files/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /files/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 50292.06it/s]            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /files/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6aiEK6JH44o",
        "colab_type": "text"
      },
      "source": [
        "## Displayers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHvpL27NcQuZ",
        "colab_type": "text"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1AIpemgYs2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(img):\n",
        "    plt.imshow(np.transpose(img, (1, 2, 0)).squeeze())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBpA-p6IYzL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def displaying_data(dataiter):\n",
        "    # obtain one batch of training images\n",
        "    images, labels = dataiter.next()\n",
        "    images = images.numpy() # convert images to numpy for display\n",
        "\n",
        "    # plot the images in the batch, along with the corresponding labels\n",
        "    fig = plt.figure(figsize=(25, 4))\n",
        "    # display 20 images\n",
        "    for idx in np.arange(20):\n",
        "        ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
        "        try:\n",
        "            imshow(images[idx][0])\n",
        "        except:\n",
        "            imshow(images[idx])\n",
        "\n",
        "        ax.set_title(str(int(labels[idx])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMJlsZS1Y3uN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iterdata = iter(train_loader)\n",
        "displaying_data(iterdata)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fb49WIhFnTbt",
        "colab_type": "text"
      },
      "source": [
        "### Image saver"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6AnI1QjnUPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf '/content/drive/My Drive/images/'\n",
        "if not os.path.exists('/content/drive/My Drive/images/'):\n",
        "    os.mkdir('/content/drive/My Drive/images/')\n",
        "def sample_image(n_row, batches_done):\n",
        "    \"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\"\n",
        "    # Sample noise\n",
        "    noise = Variable(FloatTensor(np.random.normal(0, 1, (n_row ** 2, embed_dim))))\n",
        "    # Get labels ranging from 0 to n_classes for n rows\n",
        "    labels = np.array([num for _ in range(n_row) for num in range(n_row)])\n",
        "    labels = Variable(LongTensor(labels))\n",
        "    gen_imgs = G(labels, noise)\n",
        "    save_image(gen_imgs.data, \"images/%d.png\" % batches_done, nrow=n_row, normalize=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPmoY0IpIuxo",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4IxeGpnBfN9",
        "colab_type": "text"
      },
      "source": [
        "## Helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ujmtfCPBhRz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class View:\n",
        "    def __init__(self, reshape):\n",
        "        self.reshape = reshape\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return x.view(*self.reshape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QW3skGs0cjEg",
        "colab_type": "text"
      },
      "source": [
        "## Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaABTx4cxoe4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self,no_classes, em_dim, img_shape):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        c, h, w = img_shape\n",
        "        init_img_size = h // 4\n",
        "        self.embedding = nn.Embedding(num_embeddings=no_classes, embedding_dim= em_dim)\n",
        "        self.linear = nn.Linear(em_dim, em_dim * init_img_size ** 2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.us = nn.Upsample(scale_factor=2)\n",
        "        self.leakyrelu = nn.LeakyReLU(0.2)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.view = View((-1, em_dim, init_img_size, init_img_size))\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(em_dim, momentum=0.8)\n",
        "        self.conv1 = nn.Conv2d(em_dim, 128, 3, 1, 1)\n",
        "\n",
        "        self.bn2 = nn.BatchNorm2d(128, momentum=0.8)\n",
        "        self.conv2 = nn.Conv2d(128, 64, 3, 1, 1)\n",
        "\n",
        "        self.bn3 = nn.BatchNorm2d(64, momentum=0.8)\n",
        "        self.conv3 = nn.Conv2d(64, 32, 3, 1, 1)\n",
        "\n",
        "        self.bn4 = nn.BatchNorm2d(32, momentum=0.8)\n",
        "        self.conv4 = nn.Conv2d(32, c, 3, 1, 1)\n",
        "\n",
        "    def forward(self, labels, noise):\n",
        "        \n",
        "        x = self.embedding(labels)\n",
        "        x = torch.mul(x, noise)\n",
        "        x = self.linear(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.view(x)\n",
        "\n",
        "        x = self.bn1(x)\n",
        "        x = self.us(x)\n",
        "        x = self.conv1(x)\n",
        "\n",
        "        x = self.bn2(x)\n",
        "        x = self.leakyrelu(x)\n",
        "        x = self.us(x)\n",
        "        x = self.conv2(x)\n",
        "\n",
        "        x = self.bn3(x)\n",
        "        x = self.leakyrelu(x)\n",
        "        x = self.conv3(x)\n",
        "        \n",
        "        x = self.bn4(x)\n",
        "        x = self.leakyrelu(x)\n",
        "        x = self.conv4(x)\n",
        "\n",
        "        x = self.tanh(x)\n",
        "        return x\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZJgRIRfsxWj",
        "colab_type": "text"
      },
      "source": [
        "## Discriminator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNlERVG6CVSx",
        "colab_type": "text"
      },
      "source": [
        "**Repeated block**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqRESrsx8wgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, bool_bn=True):\n",
        "        super(Block, self).__init__()\n",
        "        \n",
        "        self.bool_bn = bool_bn\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, 3, 2, 1)\n",
        "        self.leakyrelu = nn.LeakyReLU(0.2)\n",
        "        self.dropout = nn.Dropout2d(0.25)\n",
        "\n",
        "        if self.bool_bn:\n",
        "            self.bn = nn.BatchNorm2d(out_channels)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.leakyrelu(x)\n",
        "        x = self.dropout(x)\n",
        "        if self.bool_bn:\n",
        "            x = self.bn(x)\n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZYoyM0g-rLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, no_class, img_shape):\n",
        "        super(Discriminator, self).__init__()\n",
        "        c, h, w = img_shape\n",
        "        \n",
        "        self.block1 = Block(c, 16, bool_bn=False)\n",
        "        self.block2 = Block(16, 32)\n",
        "        self.block3 = Block(32, 64)\n",
        "        self.block4 = Block(64, 128)\n",
        "\n",
        "        downed_size = int(math.ceil(h / 2**4))\n",
        "\n",
        "        self.view = View((-1, 128 * downed_size ** 2))\n",
        "\n",
        "        self.advv_layer = nn.Linear(128 * downed_size ** 2 , 1)\n",
        "        self.aux_layer = nn.Linear(128 * downed_size ** 2 , no_class)\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.softmax = nn.Softmax()\n",
        "\n",
        "    def forward(self, img):\n",
        "        x = self.block1(img)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.block4(x)   \n",
        "\n",
        "        x = self.view(x)\n",
        "\n",
        "        adv = self.advv_layer(x)\n",
        "        adv = self.sigmoid(adv)\n",
        "\n",
        "        aux = self.aux_layer(x)\n",
        "        aux = self.softmax(aux)\n",
        "        \n",
        "        return adv, aux\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNw2sfLSI4Wa",
        "colab_type": "text"
      },
      "source": [
        "# Workers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuBrwnGLJH7S",
        "colab_type": "text"
      },
      "source": [
        "## Models, Optimizers & Losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H6-5LINC_eR",
        "colab_type": "text"
      },
      "source": [
        "**Configs** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rtip5RvuDjwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#image shape\n",
        "img, _ = iterdata.next()\n",
        "image_shape = img[0].shape\n",
        "\n",
        "#number of classes\n",
        "n_classes = 10\n",
        "\n",
        "#embedding dim\n",
        "embed_dim = 128\n",
        "\n",
        "# checking for GPU availability\n",
        "cuda = torch.cuda.is_available()\n",
        "\n",
        "#Learning rate\n",
        "lr = 0.0002\n",
        "\n",
        "#B1 & B2\n",
        "b1 = 0.5\n",
        "b2 = 0.999\n",
        "\n",
        "#Path to save trained model\n",
        "model_file = ''\n",
        "\n",
        "# numper of epochs\n",
        "n_epochs = 250\n",
        "\n",
        "#Data types\n",
        "FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
        "LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor\n",
        "\n",
        "#interval to save images\n",
        "sample_interval = 100\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKNh_FtHF28h",
        "colab_type": "text"
      },
      "source": [
        "**Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IP5vLO6WF5uF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "G = Generator(n_classes, embed_dim, image_shape)\n",
        "D = Discriminator(n_classes, image_shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8JtSyxbF92W",
        "colab_type": "text"
      },
      "source": [
        "**Losses**  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCVb6ZrdF9Vv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adv_loss = torch.nn.BCELoss()\n",
        "aux_loss = torch.nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGNi7d0vGGqD",
        "colab_type": "text"
      },
      "source": [
        "**Cuda** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge-VebFoGEYa",
        "colab_type": "code",
        "outputId": "7c96362a-9166-4642-fdf9-8a2a45bd310c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if cuda:\n",
        "    print(\"Cuda is Available\")\n",
        "    G.cuda()\n",
        "    D.cuda()\n",
        "\n",
        "    adv_loss.cuda()\n",
        "    aux_loss.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda is Available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzZfYWw8GL7a",
        "colab_type": "text"
      },
      "source": [
        "**Optimizers** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9ICEAWxBmCX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer_G = torch.optim.Adam(G.parameters(), lr=lr, betas=(b1, b2))\n",
        "optimizer_D = torch.optim.Adam(D.parameters(), lr=lr, betas=(b1, b2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-Wm00T5I68x",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Pzt5ypjSAwM",
        "colab_type": "code",
        "outputId": "e8caafea-f21f-4915-bb48-139738416669",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "min_G_valid_loss = np.Inf\n",
        "min_D_valid_loss = np.Inf\n",
        "saved_epoch = 0\n",
        "for epoch in range(n_epochs):\n",
        "    G_valid_loss = 0\n",
        "    D_valid_loss = 0\n",
        "    for i, (imgs,labels) in enumerate(train_loader):\n",
        "        \n",
        "        batch_size = imgs.shape[0]\n",
        "        \n",
        "        real = Variable(FloatTensor(batch_size, 1).fill_(1.0), requires_grad=False)\n",
        "        gen = Variable(FloatTensor(batch_size, 1).fill_(0.0), requires_grad=False)    \n",
        "        \n",
        "        real_labels = Variable(labels.type(LongTensor))\n",
        "        real_imgs = Variable(imgs.type(FloatTensor))\n",
        "\n",
        "        gen_labels = Variable(LongTensor(np.random.randint(0, n_classes, batch_size)))\n",
        "        noise = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, embed_dim))))\n",
        "\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        gen_imgs = G(gen_labels, noise)\n",
        "\n",
        "        adv_score, aux_score = D(gen_imgs)\n",
        "\n",
        "        G_loss = (adv_loss(adv_score, real) + aux_loss(aux_score, gen_labels)) / 2.\n",
        "        \n",
        "        G_loss.backward()\n",
        "        optimizer_G.step()\n",
        "        \n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        real_adv_score, real_aux_score = D(real_imgs)\n",
        "        real_loss = (adv_loss(real_adv_score, real) + aux_loss(real_aux_score, real_labels)) / 2\n",
        "\n",
        "        gen_adv_score, gen_aux_score = D(gen_imgs.detach())\n",
        "        gen_loss = (adv_loss(gen_adv_score, gen) + aux_loss(gen_aux_score, gen_labels)) / 2\n",
        "\n",
        "        D_loss = (real_loss + gen_loss) / 2.\n",
        "        \n",
        "        D_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        pred = np.concatenate([real_aux_score.data.cpu().numpy(), gen_aux_score.data.cpu().numpy()], axis=0)\n",
        "        gt = np.concatenate([real_labels.data.cpu().numpy(), gen_labels.data.cpu().numpy()], axis=0)\n",
        "        d_acc = np.mean(np.argmax(pred, axis=1) == gt)\n",
        "\n",
        "        print(\n",
        "            \"\\r[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %d%%] [G loss: %f]\"\n",
        "            % (epoch, n_epochs, i, len(train_loader), D_loss.item(), 100 * d_acc, G_loss.item()), end=''\n",
        "        )\n",
        "       \n",
        "        batches_done = epoch * len(train_loader) + i\n",
        "        if batches_done % sample_interval == 0:\n",
        "            sample_image(n_row=10, batches_done=batches_done)\n",
        "        \n",
        "        G_valid_loss += G_loss.item()\n",
        "        D_valid_loss += D_loss.item()\n",
        "\n",
        "    G_valid_loss /= len(train_loader)\n",
        "    D_valid_loss /= len(train_loader)\n",
        "            \n",
        "    if min_G_valid_loss > G_valid_loss:\n",
        "        print ('\\nG Validation loss decreased ({:.6f} --> {:.6f}). \\\n",
        "        Saving model ...\\n'.format(min_G_valid_loss, G_valid_loss))\n",
        "        min_valid_loss = G_valid_loss\n",
        "        torch.save(G.state_dict(), '/content/drive/My Drive/Models/G.pth')\n",
        "        saved_epoch = epoch\n",
        "    if min_D_valid_loss > D_valid_loss:\n",
        "        print ('\\nD Validation loss decreased ({:.6f} --> {:.6f}). \\\n",
        "        Saving model ...\\n'.format(min_D_valid_loss, D_valid_loss))\n",
        "        min_D_valid_loss = D_valid_loss\n",
        "        torch.save(D.state_dict(), '/content/drive/My Drive/Models/D.pht')\n",
        "    if epoch - saved_epoch > 15:\n",
        "        print(\"Early Stopping\")\n",
        "        break\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[Epoch 0/250] [Batch 937/938] [D loss: 1.256521, acc: 60%] [G loss: 1.400350]\n",
            "G Validation loss decreased (inf --> 1464.384704).         Saving model ...\n",
            "\n",
            "\n",
            "D Validation loss decreased (inf --> 1255.824039).         Saving model ...\n",
            "\n",
            "[Epoch 1/250] [Batch 937/938] [D loss: 1.096992, acc: 73%] [G loss: 1.365475]\n",
            "G Validation loss decreased (inf --> 1384.953418).         Saving model ...\n",
            "\n",
            "\n",
            "D Validation loss decreased (1255.824039 --> 1125.678148).         Saving model ...\n",
            "\n",
            "[Epoch 2/250] [Batch 937/938] [D loss: 1.222710, acc: 78%] [G loss: 1.321601]\n",
            "G Validation loss decreased (inf --> 1331.380878).         Saving model ...\n",
            "\n",
            "\n",
            "D Validation loss decreased (1125.678148 --> 1059.269634).         Saving model ...\n",
            "\n",
            "[Epoch 3/250] [Batch 937/938] [D loss: 1.091178, acc: 81%] [G loss: 1.257431]\n",
            "G Validation loss decreased (inf --> 1298.123950).         Saving model ...\n",
            "\n",
            "\n",
            "D Validation loss decreased (1059.269634 --> 1033.413515).         Saving model ...\n",
            "\n",
            "[Epoch 4/250] [Batch 937/938] [D loss: 1.025876, acc: 82%] [G loss: 1.526346]\n",
            "G Validation loss decreased (inf --> 1248.463274).         Saving model ...\n",
            "\n",
            "\n",
            "D Validation loss decreased (1033.413515 --> 1024.530449).         Saving model ...\n",
            "\n",
            "[Epoch 5/250] [Batch 937/938] [D loss: 1.071381, acc: 84%] [G loss: 1.208181]\n",
            "G Validation loss decreased (inf --> 1205.495942).         Saving model ...\n",
            "\n",
            "\n",
            "D Validation loss decreased (1024.530449 --> 1024.264468).         Saving model ...\n",
            "\n",
            "[Epoch 6/250] [Batch 937/938] [D loss: 1.128144, acc: 87%] [G loss: 1.051021]\n",
            "G Validation loss decreased (inf --> 1161.258040).         Saving model ...\n",
            "\n",
            "[Epoch 7/250] [Batch 937/938] [D loss: 1.050546, acc: 90%] [G loss: 1.123953]\n",
            "G Validation loss decreased (inf --> 1141.154949).         Saving model ...\n",
            "\n",
            "[Epoch 8/250] [Batch 937/938] [D loss: 1.081281, acc: 90%] [G loss: 1.118292]\n",
            "G Validation loss decreased (inf --> 1129.646349).         Saving model ...\n",
            "\n",
            "[Epoch 9/250] [Batch 937/938] [D loss: 1.019491, acc: 92%] [G loss: 1.337890]\n",
            "G Validation loss decreased (inf --> 1111.378364).         Saving model ...\n",
            "\n",
            "[Epoch 10/250] [Batch 937/938] [D loss: 1.103357, acc: 95%] [G loss: 1.245787]\n",
            "G Validation loss decreased (inf --> 1106.332370).         Saving model ...\n",
            "\n",
            "[Epoch 11/250] [Batch 937/938] [D loss: 1.078862, acc: 98%] [G loss: 1.244249]\n",
            "G Validation loss decreased (inf --> 1098.225986).         Saving model ...\n",
            "\n",
            "[Epoch 12/250] [Batch 937/938] [D loss: 1.232886, acc: 92%] [G loss: 1.231840]\n",
            "G Validation loss decreased (inf --> 1092.845110).         Saving model ...\n",
            "\n",
            "[Epoch 13/250] [Batch 937/938] [D loss: 1.079225, acc: 92%] [G loss: 1.119390]\n",
            "G Validation loss decreased (inf --> 1084.440896).         Saving model ...\n",
            "\n",
            "[Epoch 14/250] [Batch 937/938] [D loss: 1.075701, acc: 95%] [G loss: 1.315131]\n",
            "G Validation loss decreased (inf --> 1076.200921).         Saving model ...\n",
            "\n",
            "[Epoch 15/250] [Batch 937/938] [D loss: 1.096232, acc: 96%] [G loss: 1.155704]\n",
            "G Validation loss decreased (inf --> 1075.293139).         Saving model ...\n",
            "\n",
            "[Epoch 16/250] [Batch 937/938] [D loss: 1.116490, acc: 87%] [G loss: 1.129285]\n",
            "G Validation loss decreased (inf --> 1063.891039).         Saving model ...\n",
            "\n",
            "[Epoch 17/250] [Batch 937/938] [D loss: 1.176607, acc: 90%] [G loss: 0.994871]\n",
            "G Validation loss decreased (inf --> 1050.397140).         Saving model ...\n",
            "\n",
            "[Epoch 18/250] [Batch 937/938] [D loss: 1.126553, acc: 96%] [G loss: 1.215187]\n",
            "G Validation loss decreased (inf --> 1044.243093).         Saving model ...\n",
            "\n",
            "\n",
            "D Validation loss decreased (1024.264468 --> 1023.205972).         Saving model ...\n",
            "\n",
            "[Epoch 19/250] [Batch 937/938] [D loss: 1.094027, acc: 92%] [G loss: 1.117352]\n",
            "G Validation loss decreased (inf --> 1038.634953).         Saving model ...\n",
            "\n",
            "\n",
            "D Validation loss decreased (1023.205972 --> 1021.838180).         Saving model ...\n",
            "\n",
            "[Epoch 20/250] [Batch 937/938] [D loss: 1.179772, acc: 95%] [G loss: 1.110329]\n",
            "G Validation loss decreased (inf --> 1038.354648).         Saving model ...\n",
            "\n",
            "[Epoch 21/250] [Batch 937/938] [D loss: 1.181908, acc: 98%] [G loss: 1.130269]\n",
            "G Validation loss decreased (inf --> 1037.942998).         Saving model ...\n",
            "\n",
            "[Epoch 22/250] [Batch 937/938] [D loss: 1.151236, acc: 93%] [G loss: 1.236056]\n",
            "G Validation loss decreased (inf --> 1034.154773).         Saving model ...\n",
            "\n",
            "[Epoch 23/250] [Batch 937/938] [D loss: 1.022025, acc: 98%] [G loss: 1.136204]\n",
            "G Validation loss decreased (inf --> 1031.380912).         Saving model ...\n",
            "\n",
            "[Epoch 24/250] [Batch 937/938] [D loss: 1.134791, acc: 95%] [G loss: 1.139020]\n",
            "G Validation loss decreased (inf --> 1030.774453).         Saving model ...\n",
            "\n",
            "[Epoch 25/250] [Batch 769/938] [D loss: 1.057211, acc: 96%] [G loss: 1.123636]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-da3fab6eda89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mG_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0madv_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0maux_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mG_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0moptimizer_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsH8f4lZI-gB",
        "colab_type": "text"
      },
      "source": [
        "## GIF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kXwlNT6eoAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import imageio"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0ygBu6dI-DP",
        "colab_type": "code",
        "outputId": "49a8c97b-6936-4e71-e72a-50024e7e6fa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with imageio.get_writer('AC_GAN.gif', mode='I') as writer:\n",
        "  \n",
        "  files = os.listdir('/content/drive/My Drive/images')\n",
        "  new_files = [int(f[:-4]) for f in files]\n",
        "  filenames = ['/content/drive/My Drive/images/' + str(f)+'.png' for f in new_files]\n",
        "\n",
        "  last = -1\n",
        "  for i,filename in enumerate(filenames):\n",
        "    frame = 2*(i**0.5)\n",
        "    if round(frame) > round(last):\n",
        "      last = frame\n",
        "    else:\n",
        "      continue\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "  image = imageio.imread(filename)\n",
        "  writer.append_data(image)\n",
        "    \n",
        "# this is a hack to display the gif inside the notebook\n",
        "os.system('cp dcgan.gif AC_GAN.gif.png')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    }
  ]
}